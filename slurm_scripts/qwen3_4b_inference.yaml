### model
model_name_or_path: Qwen/Qwen3-4B-Instruct-2507
adapter_name_or_path: saves/qwen3-4b/lora/sft  # Path to your trained LoRA adapter
trust_remote_code: true
template: qwen3_nothink

### Inference settings
infer_backend: huggingface  # choices: [huggingface, vllm]
# For vLLM backend (faster inference):
# infer_backend: vllm
# vllm_enforce_eager: true
# vllm_maxlen: 2048
